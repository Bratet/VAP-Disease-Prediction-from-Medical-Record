{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_m.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3558 entries, 0 to 3557\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   VAP     3558 non-null   int64 \n",
      " 1   TEXT    3558 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 83.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_medical_records(text):\n",
    "\n",
    "    pattern = r'(\\[\\*\\*\\d{4}-\\d{1,2}-\\d{1,2}\\*\\*\\]\\s*\\d{1,2}:\\d{2}\\s*(AM|PM).*?(?=\\[\\*\\*\\d{4}-\\d{1,2}-\\d{1,2}\\*\\*\\]\\s*\\d{1,2}:\\d{2}\\s*(AM|PM)|$))'\n",
    "    reports = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    extracted_reports = []\n",
    "    seen_reports = set()\n",
    "\n",
    "    for report_tuple in reports:\n",
    "        report = report_tuple[0]  # Extract the report from the tuple\n",
    "\n",
    "        # Extracting various pieces of information using regular expressions\n",
    "        report_id = re.search(r'\\[\\*\\*(\\d{4}-\\d{1,2}-\\d{1,2})\\*\\*\\]', report)\n",
    "        type_of_exam = re.search(r'CHEST \\((.*?)\\)', report)\n",
    "        clip_number = re.search(r'Clip Number \\(Radiology\\) (\\d+)', report)\n",
    "        reason_for_exam = re.search(r'Reason: (.+)', report)\n",
    "        admitting_diagnosis = re.search(r'Admitting Diagnosis: (.+)', report)\n",
    "        medical_condition = re.search(r'MEDICAL CONDITION:\\n\\s+(.+)', report)\n",
    "        final_report = re.search(r'FINAL REPORT\\n\\s+(.+)', report, re.DOTALL)\n",
    "\n",
    "        # Building the report string\n",
    "        report_string = \"\"\n",
    "        if report_id:\n",
    "            report_string += f\"Report ID: {report_id.group(1)}\\n\"\n",
    "        if type_of_exam:\n",
    "            report_string += f\"Type of Exam: {type_of_exam.group(1)}\\n\"\n",
    "        if clip_number:\n",
    "            report_string += f\"Clip Number: {clip_number.group(1)}\\n\"\n",
    "        if reason_for_exam:\n",
    "            report_string += f\"Reason for Exam: {reason_for_exam.group(1)}\\n\"\n",
    "        if admitting_diagnosis:\n",
    "            report_string += f\"Admitting Diagnosis: {admitting_diagnosis.group(1)}\\n\"\n",
    "        if medical_condition:\n",
    "            report_string += f\"Medical Condition: {medical_condition.group(1)}\\n\"\n",
    "        if final_report:\n",
    "            report_string += f\"Final Report: {final_report.group(1)}\\n\"\n",
    "\n",
    "        report_string = report_string.strip()\n",
    "        \n",
    "        # Add report to the extracted reports if it's not a duplicate\n",
    "        if report_string not in seen_reports:\n",
    "            extracted_reports.append(report_string)\n",
    "            seen_reports.add(report_string)\n",
    "\n",
    "    return extracted_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse all patient records\n",
    "parsed_records = df['TEXT'].apply(parse_medical_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Report ID: 2186-1-21\\nType of Exam: PORTABLE ...\n",
       "1       [Report ID: 2141-3-12\\nType of Exam: PORTABLE ...\n",
       "2       [Report ID: 2141-3-17\\nClip Number: 13453\\nRea...\n",
       "3       [Report ID: 2141-3-22\\nClip Number: 13677\\nRea...\n",
       "4       [Report ID: 2196-9-2\\nType of Exam: PORTABLE A...\n",
       "                              ...                        \n",
       "3553    [Report ID: 2181-9-10\\nClip Number: 11595\\nRea...\n",
       "3554    [Report ID: 2178-9-15\\nClip Number: 83079\\nRea...\n",
       "3555    [Report ID: 2186-7-18\\nType of Exam: PORTABLE ...\n",
       "3556    [Report ID: 2186-7-31\\nType of Exam: PORTABLE ...\n",
       "3557    [Report ID: 2177-5-30\\nClip Number: 75820\\nRea...\n",
       "Name: TEXT, Length: 3558, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Report ID: 2104-7-3\\n'\n",
      " 'Clip Number: 106918\\n'\n",
      " 'Reason for Exam: please eval for fracture\\n'\n",
      " 'Admitting Diagnosis: CHEST TRAUMA\\n'\n",
      " 'Medical Condition: 59 year old woman sp MVC found to have acute T12 and L4 '\n",
      " 'vertebral body\\n'\n",
      " 'Final Report: STUDY:  MRI of the thoracic and lumbar spine.\\n'\n",
      " '\\n'\n",
      " ' CLINICAL INDICATION:  59-year-old woman, status post motor vehicle '\n",
      " 'accident,\\n'\n",
      " ' found to have acute T12 and L4 vertebral body compression deformity.  '\n",
      " 'Evaluate\\n'\n",
      " ' for fracture.\\n'\n",
      " '\\n'\n",
      " ' COMPARISON:  Prior CT of the torso dated [**2104-7-1**].\\n'\n",
      " '\\n'\n",
      " ' TECHNIQUE:  Sagittal T1, T2 and sagittal IDEAL sequences were obtained\\n'\n",
      " ' throughout the thoracic and lumbar spine, axial T2-weighted images were '\n",
      " 'also\\n'\n",
      " ' obtained.\\n'\n",
      " '\\n'\n",
      " ' FINDINGS:\\n'\n",
      " '\\n'\n",
      " ' MRI OF THE THORACIC SPINE.  High signal intensity is identified at T11 and '\n",
      " 'T12\\n'\n",
      " ' vertebral bodies on the water IDEAL STIR sequence, with minimal '\n",
      " 'compression\\n'\n",
      " ' deformity at T12, there is no evidence of retropulsion.  The signal '\n",
      " 'intensity\\n'\n",
      " ' throughout the thoracic spinal cord is normal with no evidence of focal or\\n'\n",
      " ' diffuse lesions to indicate spinal cord edema or cord expansion.  High '\n",
      " 'signal\\n'\n",
      " ' intensity is demonstrated anteriorly and at the inferior endplate of T11.  '\n",
      " 'The\\n'\n",
      " ' conus medullaris is normal and terminates at the level of T12.  The '\n",
      " 'visualized\\n'\n",
      " ' paravertebral structures are grossly unremarkable.\\n'\n",
      " '\\n'\n",
      " ' IMPRESSION:  Mild compression fracture identified at T12 with no evidence '\n",
      " 'of\\n'\n",
      " ' retropulsion.  High signal intensity is demonstrated on the fat '\n",
      " 'suppression\\n'\n",
      " ' sequence at T11, also consistent with edema and nondisplaced fracture.\\n'\n",
      " '\\n'\n",
      " ' These findings were communicated to Dr. [**Last Name (STitle) 5465**] '\n",
      " '[**Name (STitle) 39903**], by Dr. [**First Name8 (NamePattern2) 3980**] '\n",
      " '[**Last Name (NamePattern1) 796**], via\\n'\n",
      " ' phone call at 17:20 hrs on [**2104-7-3**].\\n'\n",
      " '\\n'\n",
      " ' MRI OF THE LUMBAR SPINE.\\n'\n",
      " '\\n'\n",
      " ' Compression fracture is identified at L4 vertebral body with mild '\n",
      " 'posterior\\n'\n",
      " ' kyphotic angulation of the superior endplate.  Disc degenerative changes '\n",
      " 'are\\n'\n",
      " ' visualized at the intervertebral disc spaces with disc desiccation, mild '\n",
      " 'high\\n'\n",
      " ' signal intensity is noted in the posterior annulus fibrosus at T12/L1,\\n'\n",
      " ' suspicious for a tiny annular tear (image #6, series #10).\\n'\n",
      " '\\n'\n",
      " ' From L1/L2 through L2/L3 levels, there is no evidence of neural foraminal\\n'\n",
      " ' narrowing or spinal canal stenosis.\\n'\n",
      " '                                                             (Over)',\n",
      " 'Report ID: 2104-7-3\\n'\n",
      " 'Clip Number: 106918\\n'\n",
      " 'Reason for Exam: please eval for fracture\\n'\n",
      " 'Admitting Diagnosis: CHEST TRAUMA\\n'\n",
      " 'Final Report: (Cont)\\n'\n",
      " '\\n'\n",
      " ' At L3/L4, there is a posterior diffuse disc bulge, causing anterior thecal '\n",
      " 'sac\\n'\n",
      " ' deformity and mild bilateral neural foraminal narrowing, moderate '\n",
      " 'articular\\n'\n",
      " ' joint facet hypertrophy is present, causing moderate spinal canal stenosis\\n'\n",
      " ' (image #10, series #11), mild ligamentum flavum thickening is also '\n",
      " 'present.\\n'\n",
      " '\\n'\n",
      " ' At L4/L5 level, there is mild posterior broad-based disc bulge, causing '\n",
      " 'mild\\n'\n",
      " ' anterior thecal sac deformity and also mild bilateral neural foraminal\\n'\n",
      " ' narrowing, moderate articular joint facet hypertrophy and ligamentum '\n",
      " 'flavum\\n'\n",
      " ' thickening is present (image #15, series #11).\\n'\n",
      " '\\n'\n",
      " ' At L5/S1 level, both neural foramina are patent, there is no evidence of\\n'\n",
      " ' spinal canal stenosis or neural foraminal narrowing, mild articular joint\\n'\n",
      " ' facet hypertrophy is identified at this level, the sacroiliac joints are\\n'\n",
      " ' unremarkable.\\n'\n",
      " '\\n'\n",
      " ' IMPRESSION:  1. Compression fracture identified at the L4 vertebral body '\n",
      " 'with\\n'\n",
      " ' mild retropulsion of the superior endplate with associated posterior disc\\n'\n",
      " ' bulging at L3/L4, causing anterior thecal sac deformity and mild bilateral\\n'\n",
      " ' neural foraminal narrowing,\\n'\n",
      " '\\n'\n",
      " ' 2. Disc degenerative changes are also identified at L4/L5, causing mild\\n'\n",
      " ' bilateral neural foraminal narrowing, and hypertrophy of the articular '\n",
      " 'joint\\n'\n",
      " ' facets at L4/L5 and L5/S1 levels.',\n",
      " 'Report ID: 2104-7-4\\n'\n",
      " 'Type of Exam: PORTABLE AP\\n'\n",
      " 'Clip Number: 106919\\n'\n",
      " 'Reason for Exam: pleas eval for interval change\\n'\n",
      " 'Admitting Diagnosis: CHEST TRAUMA\\n'\n",
      " 'Medical Condition: 59 year old woman with R pneumothorax and significant SQ '\n",
      " 'emphysema\\n'\n",
      " 'Final Report: INDICATION:  59-year-old woman with right pneumothorax and '\n",
      " 'significant\\n'\n",
      " ' subcutaneous emphysema, assess for interval change.\\n'\n",
      " '\\n'\n",
      " ' COMPARISONS:  [**2104-7-2**].\\n'\n",
      " '\\n'\n",
      " ' Portable semi-upright chest radiograph is obtained revealing satisfactory\\n'\n",
      " ' position of endotracheal tube, nasogastric tube, right IJ central venous\\n'\n",
      " ' catheter, and bilateral apically directed chest tubes.  Subcutaneous '\n",
      " 'emphysema\\n'\n",
      " ' is unchanged without evidence of pneumothorax.  Left basal atelectasis and\\n'\n",
      " ' effusion are unchanged with increase in right basal opacities consistent '\n",
      " 'with\\n'\n",
      " ' worsening atelectasis or less likely aspiration.  Mild pulmonary edema is\\n'\n",
      " ' slightly increased.  Cardiomediastinal silhouette is unchanged.\\n'\n",
      " '\\n'\n",
      " ' IMPRESSION:  Unchanged moderate left and increased moderate right basal\\n'\n",
      " ' atelectasis with mild pulmonary edema.']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(parsed_records[3500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a hierarchical model for handling multiple reports per patient involves a two-level architecture. The first level processes individual reports, and the second level aggregates the outputs across these reports to make a final prediction for each patient. Here's a step-by-step guide to implement this approach:\n",
    "\n",
    "### 1. Preprocessing:\n",
    "- **Segment Reports**: Ensure each patient's reports are segmented correctly and gathered together.\n",
    "- **Tokenization**: Tokenize each report using the tokenizer appropriate for your transformer model.\n",
    "\n",
    "### 2. First-Level Transformer Model:\n",
    "- **Model Selection**: Choose a suitable transformer model (like BERT, GPT, etc.) for text analysis.\n",
    "- **Process Each Report**: Feed each report into the transformer model individually. This model will capture the nuances and details in each report.\n",
    "- **Output Representation**: Extract a fixed-size vector representation for each report. This could be the [CLS] token's embedding in BERT, for example, or a pooled representation of all token embeddings.\n",
    "\n",
    "### 3. Second-Level Aggregation Model:\n",
    "- **Input**: The input to this model is the sequence of vector representations from the first-level model, one for each report.\n",
    "- **Model Choice**: You can use another transformer, an RNN (like LSTM or GRU), or even simpler methods like averaging or max pooling. The choice depends on the importance of understanding the sequence and relationships between reports.\n",
    "- **Temporal Information**: If the order of reports is important, an RNN or transformer as the second-level model is preferable as it can capture temporal dynamics.\n",
    "\n",
    "### 4. Training:\n",
    "- **Batching**: When batching data, ensure that each batch contains a sequence of report embeddings for each patient. Handle variable lengths either by padding or by using dynamic batching.\n",
    "- **Loss Function and Optimization**: Choose a loss function that aligns with your prediction task (binary classification, multi-class classification, etc.). Optimize the model using gradient descent.\n",
    "\n",
    "### 5. Prediction:\n",
    "- **Aggregated Output**: The second-level model will provide an aggregated output representing the collective information from all reports of a patient.\n",
    "- **Final Prediction**: Use this output to make the final prediction (e.g., patient's health status).\n",
    "\n",
    "### 6. Practical Considerations:\n",
    "- **Memory Constraints**: Depending on your model size and the number of reports, you may face memory constraints. It's important to manage the computational resources effectively.\n",
    "- **Sequence Lengths**: Be mindful of the maximum sequence length of the transformer model, especially at the first level.\n",
    "- **Model Complexity**: This approach is more complex and might require careful tuning and sufficient training data to capture the relationships effectively.\n",
    "\n",
    "### 7. Example Architecture:\n",
    "```python\n",
    "class HierarchicalTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model, second_level_model):\n",
    "        super().__init__()\n",
    "        self.transformer_model = transformer_model  # First level\n",
    "        self.second_level_model = second_level_model  # Second level\n",
    "\n",
    "    def forward(self, batch_of_reports):\n",
    "        # Process each report with transformer_model\n",
    "        # Aggregate report embeddings\n",
    "        # Feed aggregated embeddings to second_level_model\n",
    "        # Return final prediction\n",
    "```\n",
    "\n",
    "### 8. Implementation:\n",
    "- **Frameworks**: Implement this in a deep learning framework like PyTorch or TensorFlow.\n",
    "- **Data Handling**: Carefully handle the data to ensure reports are correctly aligned with patients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a hierarchical model for handling multiple reports per patient involves a two-level architecture. The first level processes individual reports, and the second level aggregates the outputs across these reports to make a final prediction for each patient. Here's a step-by-step guide to implement this approach:\n",
    "\n",
    "### 1. Preprocessing:\n",
    "- **Segment Reports**: Ensure each patient's reports are segmented correctly and gathered together.\n",
    "- **Tokenization**: Tokenize each report using the tokenizer appropriate for your transformer model.\n",
    "\n",
    "### 2. First-Level Transformer Model:\n",
    "- **Model Selection**: Choose a suitable transformer model (like BERT, GPT, etc.) for text analysis.\n",
    "- **Process Each Report**: Feed each report into the transformer model individually. This model will capture the nuances and details in each report.\n",
    "- **Output Representation**: Extract a fixed-size vector representation for each report. This could be the [CLS] token's embedding in BERT, for example, or a pooled representation of all token embeddings.\n",
    "\n",
    "### 3. Second-Level Aggregation Model:\n",
    "- **Input**: The input to this model is the sequence of vector representations from the first-level model, one for each report.\n",
    "- **Model Choice**: You can use another transformer, an RNN (like LSTM or GRU), or even simpler methods like averaging or max pooling. The choice depends on the importance of understanding the sequence and relationships between reports.\n",
    "- **Temporal Information**: If the order of reports is important, an RNN or transformer as the second-level model is preferable as it can capture temporal dynamics.\n",
    "\n",
    "### 4. Training:\n",
    "- **Batching**: When batching data, ensure that each batch contains a sequence of report embeddings for each patient. Handle variable lengths either by padding or by using dynamic batching.\n",
    "- **Loss Function and Optimization**: Choose a loss function that aligns with your prediction task (binary classification, multi-class classification, etc.). Optimize the model using gradient descent.\n",
    "\n",
    "### 5. Prediction:\n",
    "- **Aggregated Output**: The second-level model will provide an aggregated output representing the collective information from all reports of a patient.\n",
    "- **Final Prediction**: Use this output to make the final prediction (e.g., patient's health status).\n",
    "\n",
    "### 6. Practical Considerations:\n",
    "- **Memory Constraints**: Depending on your model size and the number of reports, you may face memory constraints. It's important to manage the computational resources effectively.\n",
    "- **Sequence Lengths**: Be mindful of the maximum sequence length of the transformer model, especially at the first level.\n",
    "- **Model Complexity**: This approach is more complex and might require careful tuning and sufficient training data to capture the relationships effectively.\n",
    "\n",
    "### 7. Example Architecture:\n",
    "```python\n",
    "class HierarchicalTransformerModel(nn.Module):\n",
    "    def __init__(self, transformer_model, second_level_model):\n",
    "        super().__init__()\n",
    "        self.transformer_model = transformer_model  # First level\n",
    "        self.second_level_model = second_level_model  # Second level\n",
    "\n",
    "    def forward(self, batch_of_reports):\n",
    "        # Process each report with transformer_model\n",
    "        # Aggregate report embeddings\n",
    "        # Feed aggregated embeddings to second_level_model\n",
    "        # Return final prediction\n",
    "```\n",
    "\n",
    "### 8. Implementation:\n",
    "- **Frameworks**: Implement this in a deep learning framework like PyTorch or TensorFlow.\n",
    "- **Data Handling**: Carefully handle the data to ensure reports are correctly aligned with patients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for record, vpa in zip(parsed_records, df['VAP']):\n",
    "    patient_record = {}\n",
    "    patient_record[\"record\"] = record\n",
    "    patient_record[\"vpa\"] = vpa\n",
    "    data.append(patient_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda for training\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 2846/2846 [06:42<00:00,  7.07batch/s, loss=0.558] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 2846/2846 [06:45<00:00,  7.02batch/s, loss=0.353] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 2846/2846 [06:46<00:00,  7.01batch/s, loss=0.275]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 2846/2846 [06:46<00:00,  7.01batch/s, loss=0.26]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 2846/2846 [06:46<00:00,  7.01batch/s, loss=0.253]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48024316109422494, Precision: 0.25900900900900903, Recall: 0.8984375, F1 Score: 0.40209790209790214\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Tokenizer and BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Custom Dataset\n",
    "class MedicalReportDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, reports, labels, max_length=512):\n",
    "        self.reports = reports\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reports)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize and pad the reports for the patient\n",
    "        tokenized_reports = [tokenizer.encode(report, add_special_tokens=True, max_length=self.max_length, truncation=True) for report in self.reports[idx]]\n",
    "        padded_reports = np.array([np.pad(r, (0, self.max_length - len(r)), mode='constant') for r in tokenized_reports])\n",
    "        \n",
    "        # Generate attention masks\n",
    "        attention_masks = np.where(padded_reports != 0, 1, 0)\n",
    "\n",
    "        return torch.tensor(padded_reports), torch.tensor(attention_masks), torch.tensor(self.labels[idx])\n",
    "\n",
    "# Custom RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size=768, hidden_size=128, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Prepare your data\n",
    "reports = [item['record'] for item in data]\n",
    "labels = [item['vpa'] for item in data]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_reports, test_reports, train_labels, test_labels = train_test_split(reports, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create dataloaders for train and test sets\n",
    "train_dataset = MedicalReportDataset(train_reports, train_labels)\n",
    "test_dataset = MedicalReportDataset(test_reports, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Instantiate RNN model\n",
    "rnn_model = RNNModel()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} for training\")\n",
    "rnn_model.to(device)\n",
    "bert_model.to(device)\n",
    "\n",
    "# Training loop\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=1e-4)\n",
    "\n",
    "class_0_count = sum(np.array(labels) == 0)\n",
    "class_1_count = sum(np.array(labels) == 1)\n",
    "total_count = class_0_count + class_1_count\n",
    "\n",
    "# Calculate class weights\n",
    "class_0_weight = class_1_count / total_count\n",
    "class_1_weight = class_0_count / total_count\n",
    "\n",
    "# Initialize BCELoss without weights\n",
    "criterion = nn.BCELoss(reduction='none')\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    # Initialize the progress bar for the batches within the current epoch\n",
    "    with tqdm(train_dataloader, desc=\"Processing Batches\", unit=\"batch\") as tepoch:\n",
    "        for batch_reports, attention_masks, batch_labels in tepoch:\n",
    "            aggregated_outputs = []\n",
    "\n",
    "            if batch_reports.size(1) == 0:\n",
    "                # Handle the case where there are no reports\n",
    "                continue\n",
    "\n",
    "            for report, mask in zip(batch_reports.squeeze(0), attention_masks.squeeze(0)):\n",
    "                inputs = report.unsqueeze(0).to(device)\n",
    "                mask = mask.unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = bert_model(inputs, attention_mask=mask)[1]  # Get the pooled output with attention mask\n",
    "                    aggregated_outputs.append(outputs)\n",
    "\n",
    "            if len(aggregated_outputs) == 0:\n",
    "                # If no outputs were collected, skip this batch\n",
    "                continue\n",
    "\n",
    "            # Convert to a tensor and process through RNN\n",
    "            aggregated_outputs = torch.stack(aggregated_outputs).squeeze(1)\n",
    "            predictions = rnn_model(aggregated_outputs.unsqueeze(0))\n",
    "\n",
    "            # Ensure predictions and labels are correctly shaped\n",
    "            predictions = predictions.squeeze()\n",
    "            if len(predictions.size()) == 0:\n",
    "                predictions = predictions.unsqueeze(0)  # Add a dimension if predictions are a scalar\n",
    "            batch_labels = batch_labels.float().to(device)\n",
    "\n",
    "            loss = criterion(predictions, batch_labels)\n",
    "            loss = loss * (batch_labels * class_1_weight + (1 - batch_labels) * class_0_weight)\n",
    "            loss = loss.mean()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the progress bar\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "            \n",
    "            \n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_reports, attention_masks, batch_labels in dataloader:\n",
    "            aggregated_outputs = []\n",
    "\n",
    "            if batch_reports.size(1) == 0:\n",
    "                # Handle the case where there are no reports\n",
    "                continue\n",
    "\n",
    "            for report, mask in zip(batch_reports.squeeze(0), attention_masks.squeeze(0)):\n",
    "                inputs = report.unsqueeze(0).to(device)\n",
    "                mask = mask.unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = bert_model(inputs, attention_mask=mask)[1]  # Get the pooled output with attention mask\n",
    "                    aggregated_outputs.append(outputs)\n",
    "\n",
    "            if len(aggregated_outputs) == 0:\n",
    "                # If no outputs were collected, skip this batch\n",
    "                continue\n",
    "\n",
    "            # Convert to a tensor and process through RNN\n",
    "            aggregated_outputs = torch.stack(aggregated_outputs).squeeze(1)\n",
    "            predictions = rnn_model(aggregated_outputs.unsqueeze(0))\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    all_predictions = np.array(all_predictions) >= 0.5  # Convert to binary predictions\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall, f1 = evaluate_model(rnn_model, test_dataloader)\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
